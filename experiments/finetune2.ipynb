{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from moondream import detect_device, LATEST_REVISION"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "device, dtype = detect_device()\n",
    "print(device, dtype)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda torch.float16\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model_id = \"vikhyatk/moondream2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, revision=LATEST_REVISION)\n",
    "moondream = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, trust_remote_code=True, revision=LATEST_REVISION\n",
    ").to(device=device, dtype=dtype)\n",
    "\n",
    "moondream.eval()\n",
    "print()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from IPython.display import display\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, split=\"train\"):\n",
    "        self.data = load_dataset(\n",
    "            \"project-sloth/captcha-images\",\n",
    "            revision=\"refs/convert/parquet\",  # type: ignore\n",
    "        )[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        return {\n",
    "            \"image\": sample[\"image\"],  # Should be a PIL image\n",
    "            \"qa\": [\n",
    "                {\n",
    "                    \"question\": \"What does the text say?\",\n",
    "                    \"answer\": sample[\"solution\"],\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "\n",
    "datasets = {\n",
    "    \"train\": CaptchaDataset(\"train\"),\n",
    "    \"val\": CaptchaDataset(\"validation\"),\n",
    "    \"test\": CaptchaDataset(\"test\"),\n",
    "}\n",
    "\n",
    "sample = datasets[\"train\"][0]\n",
    "display(sample[\"image\"])\n",
    "\n",
    "for qa in sample[\"qa\"]:\n",
    "    print(\"Question:\", qa[\"question\"])\n",
    "    print(\"Ground Truth:\", qa[\"answer\"])\n",
    "    print(\n",
    "        \"Moondream:\",\n",
    "        moondream.answer_question(\n",
    "            moondream.encode_image(sample[\"image\"]),\n",
    "            qa[\"question\"],\n",
    "            tokenizer=tokenizer,\n",
    "        ),\n",
    "    )"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAAAyCAIAAACWMwO2AAAtPElEQVR4AbXd9a8l5bLG8dnD4O7urgd3J0AgWMLfRggEEgJBLsECwd3d3d3dOdjcz9pfzpsdzu45uTc5/UPn7ep6q556SrrXWpthyXPPPffzzz8vX778t99+c/7n/GExJX/ppZd++uknCr///rvzn3/+6fzrr78+9dRTztbffvuts8MtNp9++un5q+V//PHHBx988M0333z55Zckzz77bHKSFj/++KPFm2++mQXW3MomUPCEMGXGg/H444+zTNjZ4pdffnGG0y6LYSH5sO/WMIiBqXjhZ1mwxQtbl/yy4HAZCbnjlzBK3copyYsvvjjTXr78+++/d4Yqg/y2scs2Wj/55JPz6n/hLwrW2GnNuCMdANhxmZGFG19//fUvvvgiyVtvvTUUnnnmGbEwmDUK8TnFwxNPPJGRH374wWJUC32XwbbIPjxL0oZJeH8Lxq1F5YTxpTgiJSPOyV944YUBl7CKcevCCy+85pprvvrqq/S5Dx/Q3333XVs++ugj688///yRRx6BZyBui0u7HnrooS5tcfnZZ5+J9uuvv3777bdLW3edKdgy4gpeDEKFcQoJ27JovMPXIHcoc2otXhsXlikhJJKXkMeiwzs8w45IM+WMyccee6xLQVm0F86FzUCuICjQJx9F08bO9913H3eO7MThrbfeevfdd+ttOjUz7++9957zaPIRwqI8AI9nZod+7qqB7OSR2hIxp7cwGHan5DDhi3KVS5N1l9A3nLJTMNawvvzyy3bJ30UXXXTJJZcIBjh8le/0g1gybrzxxv+ZP3S/XSWPu5ojzXYx/v7771eX5EXoVvlbGH/65FzIh0sIC6EJOhUvAA8//PAw3sJ2gRdvycg1++ykT7NbnV2+9tprH3744WWXXXbttdeOAQZGfVJ9M+ugrP3wZuGIzG7J36uvvjpsjrsk6mamPd9OCkj9AePy3XffxeSVV1558cUXv/POO/Weu/fff3+UZo2E8hQPQtPqFIrUIpz2jnillZym82xiRZOFwzb913pK7q6Joj4yrc5GBxge6iDT7EQWfS4dSDGQxBxT5DRbW6iP1ixIgIoJBkcZhKdFBhfWGQm+3OXxlVdeGfZtyYi44AQYfZ9++inNbllwFP6peFmjNgiF02Vm8+ssOvWaXJgkVS3L4QTMXd6VlIqUbA/TEj9MWZB4qVgoad7DZks2u1s/kD///PPxjFgKJUWCyGWdwohOVcEAQAib9NWZOv6PeccD4xAKFob6yqKKzI5zPbMk3FTlr4dUWZmSF5UntzylqVZsF9Inn3zC6BtvvFEOQp+OkOSjzqBJP1901BBePv7443vvvZfx5pOFLTECa/EQ4gW/yWMz7qzRWsBlK/y8ez5i2V4eXUqbSemJ/MADD4TQLexPxQstBWf2hz5J+vB4cSnGvMcvVPJEzjJlRwvIzS1Uk2S5Zxk54ULkrRU9ufAdWciXu6heyDN4NDklb++829kpR/y2SD76hH7IuXBrBTwAyb68xHyRtraX/SxkfzaxshWact+b6ZS8Cq0C2GVO0bCjA5xDXPw9jOiADlbGKRjmNMNRtkh0tiDJO+inwJ2yIyySvBdPfhmXYArpW+c3HkOSgoeOoOD0UL7uuuvUtGqDBym2T8UbHvwwpaNc9jKUfvjd5f3OO+9MmTAwXRoeFoUfqu4++OCDQz46imQMrcCTtPjbkI5qoXnSUdByIIUHe3Zpfme+FOXIrydsDzW3OiKWWkNoigdcoa67bRkvhV2yxgtf8M8Kq0q0sKcE5G9RuWBQY+zT8UypjQhtdNSLprQ1BUVw1VVXnXPOOTFLUkEEzjqmOIp0ckIDRoVlOXktpbmrPOgXNp+oTE282Bt9xcl7n9HazjtUEgCtyJWILTyShGrReO1iDYN24V3LurQuuiob43mX2uTULBxF6gwYR9VlE9Td/LKGN/FSIBxotZMDA7lL3xZjLP5pFmlBoT0AyGHNDLPFYd3rGlNu8RWr0pcdCmJP2XmKB7uyU+3S5Nde4cczCcBQATzH05prrkljbm5utdVWE/l222238sor42JR+ZL5g+l11lnHUqZ33HFHFjmgr+1WX3317Gy22WZLly4Vnnzsueeee++9NzWzYeutt15jjTXkeNmyZfzSR7oXo/333z/jzslhM1R23XVXaYPVLnKuN910Uzb32Wcf9hHNAk432GADIcC/xRZbQGLvWmutxTIhBZFvueWW9MnXW289QjYdvcnttddeU/FiExue78p6ww03FCB+NtlkE0iEo2EOPvhg1jAuasDYXHvtteVslVVWEaDXA2ty+Nddd1052H333d2Cf6utttp4443JV111VabuueeebbfdlikUCRmfJWmllVbCWE2LagqgKo5jjjlGXCY94zwaTgwK0KMfToEr+uOOOw54gas/EmoeZLwA5mCZd3VAXo4Am+KBmrvYAAxgfnnZaKON0mcf5+6yj2Ex/pUJPmh7Xdhhhx3k1WaeDjjgAOsit6gUUKlEWhM6jEfxoAxxgsQRcuF2psYmyR577JGyCgDI2osO+9mRXewfeOCB5J5i7DNoXfmyA7FIIJYJ2MwbvtTHfvvtJw377rtvdhSZ7NpI39P88MMPt8CseSNJrB100EEkQvjHP/6hMZS+NDhbP/roo4cccoi9jsqaJuQqlYttttkGReaQHCCEZYEIlo6s2xIA2PhlRxaNJU9eyWBEQSCE30MPPZQv4KGSKhvZ13WQGzY4EbhyUQq6SNNuv/32lHFiOx0NQIHa8ccfj0bBMq7U+FL3UkYBPJzzC4xLpGkqFUZCDVquueAXKvjlHQzKLNuLZ2VBxy1nEnILnbP55pvjnCaPzggRtVxorbazU8pAnYMsHmXXo1dhyXd6bvOqGCNRqHY6ZJpRC4xzZjDwJEN8y7E8yeL6669Pf/hjhJoHn4wi3S1+HUDTsdEuTKlOg6eQ2NfuuLPX2GPfGhfO9Alh0DEnnXQSzUIQpLEHHrMgkfcWZW8Dhi+73N1tt90oAMmaAxLw6Ht6SiEA0iDTmr67YNvFLzt0oNUGzjbC7Nh5552xbJ7pYHYUDfumCFMqA1q5EbgGY5/NXXbZBb3w8Msm46oQch2v9fEjozT5RT78rDHFBWCyG88KXb5EROiVA4GmtbXxL3B22BejXeqJO8COPPLI4Lkkx7YQFJkZzKxbHTYKQWWP4QJbqJQEqFqrPKZPWRRsClZ0hHNoqpABQpxxqpyFhAtTBG4xQ0BCW2xMeKGppQTPDWRuEXoV1awm7SgddLCviunDmpEBCC+zmTk3B1ClZs2UjIqTZQCkyi0Su0AqYezIE2ww02ffJADGmgVCOPkVjtCs3SKMI82Da5jLnJ62yxQRo35IR1a0GaLpSBKnMADJOE2xwGZOy6hhIzcsOEDFlclhwKgGNAJJUxHY6EsjsMEglCSJqbmlgS/WHIxoFWePQhMUcpoqjzWs4kQpX3311XJ08skn45PxmeMlS4woX4ryCJIh52GtqqxFdNddd5E7hCYicjRyWnMaNvD0OGMQLerDi5eCHklnH/kmnz6vMUgAowmbFzLNQB7trJFbL8OUgzM4tJGzfOPLzHcwwaIA0Gq/JwJkupNc5tgFxfuHhvBcgFLT4MtGctDRoYRtx7j0YFYM1SsL7HBXVKAbwh5tFvAgQpxQCkYiGZFgqEwsGyWvt0VrBX3UUUdZUObUwQ6P2HELlZUOitNxiw6n6tIWsI1Dgfj2QYAyp1BQYw28eQzhYYcdttNOOyHam42hW/VLNhhIUNPKjinIlYUhx4XaZV96lAvqEM2FjWpF1BRUCYMilWPjUyUhRxZQh0+wzz77bIzx7oAcHh5FrW6kiV++lDKz5o2IbES+OcqXwxZ2JMvhEgyQ4BQa/oXjDZWOAyQ62KavIhkEW93kF0j1wKMeU0OKQSrBFmzeQTUd8ggGNc0sujkQ6XGgz1i04MNm9cE0r/ajW6Zhcibnm4KUw4ojPiDGgo0cSKc3IfJoaheznpvktlg7QGTHQgVULrUIj5JELh5rja6w+D311FMJPXSER+4uOoB313jny4HrIhQb2Bh0KEctTg4SC+BhWYtzSqh0AiBYoWGk5473FVAVtG7Bl6RyKkZPAWCAN4c8d9gHQyDKkVD6lZFaUayAKZfw8AuPQajo1asKUB/AV5FRwa+80uQOvRZlVynLnB9kpAlyg4dTmLWTeHGOIsj1JF+QMEsOObPI11GEvhy3EST1F8PU6HgUUEMRd2Wqs0htpKBuqgQRAYAu1LFvrTlRAYCWkFxoG0z2QjKrPlXGLhacOwRDjiMRijZ28GVsDH3VJlVVYd+L6Ej60Cs1drCGR76zSV5VAeo1VrSgq4CEtsDnoV6jYBkG0MUmDBUpYHbkz9TEDke2Q1gy1CIwcKKJ2m233caLaWQYmBz03SXR8aqhNrBWB9qDKY6kE0LseDGSNuzbBRKaxIVfnBrM0GoAxYS0wFRVnHKt6ZUmGMZSn4KZhdzrto2s2aUlJAkYkPSJjSw4M86RQwniB4AaWyHSDxjkwneceOKJonOpqpSI7UJABa40DNL4dVd72MiXLEgfCU2HIUfChYQ6XFIjoe8sECEwJWrKMo4TIbPgknESC2o2Ys9aYbkEmF8xzj5tkMKEEWXLuoNRpFi4JUhhW9MGqyxiSuugFfXkoGDz9ttvh0O1SQ8EtnCDAkbkRpWY0pSx6WDfY8VvW3rXo4opQdK0F1D67tqunoSnONxi0KxiQVT0WWCTKUUgZp1nhDACrUcwACzYZTCoA2pitNGrgEqiIH/syxn70S0K+pgVHY9umRPW2FD0GsDYs0t5qX5gjA14dI4HojBRoVL59Uhlqucvv2y6xK38KRfWoNXDOoGycOQDZjY1AEdA4sThlr2GnALiCPMwHH300WBLrbGBHDonnHCCXHKkvKDVKlIgEbMKnZvDJJzqkhERkRi9cupQ+qhQ2WKxnVl24HQmgccaacixyxuhMzwqDM92wW8KsilfXFOTOwq2o0J2Zt8DyRMrYLHOYqaNIuGJ2U50yJzwcJG+fFgzJK/oQIpJ65FUi6PSCynGLSQbUPYpC0DvOjMCGWrc8lJCubarRZpkwAiMgo2MuHTXFttZ1oWMqBsNahiobIDZlDzByxyPgAlSIlmQV3GJ0aW9lFmGll8Go0+O5aDQUG8X/DTdlRgAGjDyilx1Bo/5J7uQhBY8jwM8SBsvLABjF65UJO+qPH3F7S5TvFsgkC9V1ayqGcjrWPxLBKcWhEKQOZzYiytnLgBQKALHhrcC9jWeKQgns/CoDHKFxabnOzvw63ZFozHk/fzzz2cT51CJQlAcmTjAUHbpDIOzglHBfNU/aBcyKtg3jymwM/sILQEuAi0fMc4TCmodLMMnSdRMv1xWwhBID7ne0h8aKzsWMkTuoXbppZeCa43ZXuMQLaPi8e0ArHDIHAWHoWpsuOXtEgvsE6oJ88CZa4VOgdnY15H+GsKZd5pGKTWhiuLYY4/FUbyoe43BoF5HtDC5pqwupcRGs4dZbypy4FdLdIeZXxYYpKM61TS63FJtwMic7zswI6kqSY5ZU16UazzRcceCziSRDINQsfKODWoCYbAKxoOKIaSgwiyw5EVbLsA2R1FNXo7xQEG9ClymGVEx2YTB3LKFPuSM24sWOPEJj406HB7BotouWVNnTMHDvl2l1UwCRq5VEjVre3UgnIDRYQcVhA72e7zgYSkq3bDBgVkOaDONkaaFDdi0LgEsApS+743oOzDS5xHKMBlCMz/zBaEifS2pyETOjvDIIROSepeYtkcTO6gUHheSx2bZ5bqeA9Ve8ACAHsuYpWO7uvFmrcI0gznBLCNyLByvgJxqZWAUkIbBlCeLTJADJjrdybUKYEH/QUJCDiQLxa4QTQghCCTYqSkpfQWbTwZQNasowMM+bCwoSrcMHncdMMu3u5CoGxJqFZPw7cWzyjCKjAHbbXTAM8U/VDiBWWXotBtuuIELBkXnc2uOPKYtGGSnCkAC4x476JVxCKfs02efQS8wmo0diSbRsdYAC8HQiSj2Zy80tAtekdXfzt6/jEF7OONVOVvboGzNWPrsarv0M+dLZ8GQKAjKDo7RLcHCZsf8wJSywJHsSiQFI9TYYE2SnHUGL+aWW+DSbM67FL8z4liWFcPPO5Ptes4DvppjQSeROHvC0uTFt2sVtDWbjAhNKfBLAXhHj2OthRBtwA4Y5BLTm6mFIhCFUvMIpuALfX8l4a5BqNxNIzBACiGJscc+rti01+CPappgYIBN3FqYIsLHJ6cVHBoNA/qi1iqoA5vTKf6NfD+BezjYxTjkBvYRRxyhlxAOhrOGsTBX3FWC2o8X2RSREKDC4ZR98Dzm1DrMcUiTHZTyyKwQhE8iX0KevT95LtjmnkMCkKuKhUdOYhIk13OFragFiSlyCw3HjrUxyyhCCV16yCY3NihzKSt6Wr2j0povfvlysCwftpAYLYJXGYJ3ywgRNn12GHQXiSwoYgOfL7zQx5FLdsjNSDx66IAhEN7pKyYLw4ZEhuwCyUuVpxjMKGOEF1H3LFNqlHFtKKpv7YE4eMC2kWWFwouWE7jEp4D36tVGOsYD3tJnxKXHFhgiQqwtdKB1lifnIDGrat116fXLz4JcmwfoBX5R/g0MeFj2CiE01hhBlFicBShk9qnhgR1rI8oARhrOlYVRQjhl33ZxMc6aPmGkj0cCh8dGzAuZKbyBMYcItpxNRRzRAwK/fDMhbUaIBxa7atNdmu2XD0xJswBQoCzMCcTpMAqSmpxEwjjGCztR6XIcSo1fWzSQwsKy4GMBYjEofcrKBRjAVACb5g3w5rCOdNcWLzFSrsW93nk5lRJVSC6uMm2XuyacjPpe+5RTTgHYFnG59Fi0pi8oE1di0MIyACiDAQ80PUmlihEBQg6VW7gC3lzxk5xdwLPjuak3WFDTpgIhHgCAWW3pGTkAEkti50JEJmUZ4VRNu+tlQ/oVCjsdU/yLDgNACgTJVbNm8+2uMHkB0i2NkZ0RoDniSQUAdxggXzS//IrUdl4QK5XsyAioFvpT2Zh5kUYy+8kTJrZEpW6oYlY8qmp2e+lSY1+01nTw4swHmuirKtCF4aUKaNCVCH577yH3cMyTarP21IADdM2BVgfXsNIpcuFZyJw2rQ+ESkfwMiExytfAM8PgYYdZZ4Uic2zKOmswjE8kGrHxQxMeCKVcOIqvFhKvQ0RKVuAGg6ZkHCSdYxhj09oujaGw0KdTeWSEMn58k4Rr8Gy3sczxixCXdakio2CiCB886ypJk+ATgDy2xmovQ3S8O1dVeHDppW2Kf+Vr1vb1ijnEJndiFDLjYhdg2FyKyxnVztm3tgXPU/bJ227CVVW2sKMARKGg1QNr1ZmX2tmP0PgyvjjQfwvdaxqEqve0c+lMX4UKo3yodBaFbbzz4VVRSNghVDpKEALNrT68AFIe4ZHQaZ4pBawpSkINRM1IsO4uNQdrvvnElLJj3zxgil8VYDuQChqV5ICFVuN6cbGXxCuC+BUKnN7P4K/o2aRmCOFIIk07prplo4ThRDXT6dWKZQCSqyp1ZsIBDDww+BW+KuwjPQvaCdGAIdPs9OJlr5/wlKZL71jc4ZNNC3bwIJysIR9+4NUiJinAvyj/HLmLZ4wpcfPPr4egoohH9oGUX3YQyAKEbqkSL4UjTAvHlH1NoqUxb+KOFAtZVysVr3QQilFTMTL7AChm3Gl9XtEnWhru4YiQe4dhIEhAgaMvPBtdwqf76Qtej7olPXybbSjTKDMfy5apcc2NNWngBWvkFrpEuaC4lHBtIVTKaMKRrDCry+lrRHigcikAGOgoF0xRM5kQCgYLgLnlXFb4NVSMDcXEsi1Ypsa1Saap/DDnrrUHB0eqCg/aQAXwQg2n4mIT8moOYyyoadHZglllB5VhJvyqClrxSjYYttNpDNsrKG0gQAxwgUNGLCQJHl+sy64wk+NH7PE2xT+QXKTPr3UumJVp8ZKwYK5rKmlik7IQlAh+BKLIaE7ZJ0cvShFYvMJUAzAbBPipZsRorUuXmjEwqQAR2oDNmPLy6LnDsdIh9/hEB6LpM4fc1LS4mUdB5tjhJjkG7SVXYULiNTXoG0JKgRxKt7wJSmTJoyAGe5mSJ+/F4rEXDH89YayiQwXAybjZgwuF5fXWLS86QKLJRjhllA4uQGJBWbh0UBYCNSHXfxoa0ZUvBUll3xbWzCp4gCGBAcieraqTdy9AJqunPAs20uSUd/Zd8ohi1vDGmre9hrRb3rR0iNDwYxfvhLKiqsRuu6MqcYkinVk3ip0mPAxa6F53LVRMzFs7cIJeaaUJJ4l4mepBr/Kg4oJQKnGoCqsYvLlb89jlFbbCkCCXbDo75N2ZfcNVdAJxqavNXSFbLzUeRMWlchYkUtx2Q8/JMQdMIFHRECJaxVSF/C38HkteRUiNvFcEBm2Z0tffiBCMLbIiSPr60tOq4rBX8QHmiHdgKMuW1KpOC2PGcLbglAXWyjqm8O57Tr3BjoKTDxILI4SaENDhrhDwqFwUTa+GGEcfR5w6qxu3LKDFfq+etohXwuSPX0SVdWnAp1KWTn5NL81gb/OSmoeIXZLBAh0umPWnVAYGfa846hIPng/eKASl5uQeSJqKEs4qg9B2eTFvhC80M4mONTUeuc67QqlK3O2VyF11YG4hIW69ImsqQpfyRZ9BwOCxlg5bdAKEnKoQhADgkr6HAAVO5UL6aMLg1uyPBhUjPdeMSkkFobwkA4/KBYk2yIcNGDGurcmb8IRt99lKMELt+xJyGZrStx2JnCKLcWGodLEhDvUQkyMrBvErSCn06oApDyxylrEjl6IVAmtYUHCsCUpBMGgqgOEAWHNjwVc7jFMAoE8xOkfU6klxiJ3cwhkDzpyqA+Wu+rHhIcIaR+6aLqAat5AoSnUQrSi2kBsVJg2eFOauXRLpYBy2LNio0AkFq+glhh0M9AUEv3JmZKIFYKFZKOVbbrkF1YqVxMQVmqKBBzOo4BQ5+DQa/NmWYNnh3YJlZzhdikseoxfP0BKyg4fqmAXIU+aCfNHvqzBzxRVX3HHHHbb3EqUGrJeCrm6sHLw684ca+Mj5E7yoEAFfC/XHHxCULfQBx0JCHx7pCNKtPnrYuKg+hXbZ6OOV1PIox8xqa5WERK6p6Q9RwcYsCbJckjtjhxfpZ8oIVEkqD/VIgVx6UG9XVcImhPAI2WGLdBpa1pJtGmVWRPY6N0WwqZgoq1F1zDIejEmw6Sss0SlQck86jsglm008KC8IeZE/77Yepsx2CMf2DrvUBIkEQ+uBiBAzQCcwa5fQGNRa9BUiimCTv7x4CPIVe2hxuNSx7KDirLPOMvwYF4IzXyoSBtUsv+PRBqrKJmfcIxhmykw5m4vwI0GkSfiir68oa7Yslyzxcuru0orAtWIybOwUD5Zz2QTKn9kgEvrM8ccufTyqU7toIhQjMFmTkONlSp9CD2NxSjkeJUyeBMyLOmsOU7PWoJLq3UjPaWtBgs44ZVVoAIAEsIAFopgE6XBpu0kj8joE3Tgy9l3yKz2UefcBSv6oSVtZYQ0JAuQdIaJwl3EGvUZgk/fqSQPIFokFtXSomWQNUYBVM7/4gZNTKXdpOHlwn3nmmZ6eImr2GJne2xhhDbcAaBWxMGjcUlPfiLWdkF9c0XdmllBj8+uARPVzh1hq+ZUXOurGpe0iEqaQy6O4JNoab/Kb3N7yC5K7LHtfyrWMQMWC0eiDpy32ygha7FrKChCuUQw0xrHgzR1x1QohCbsUNEf6dpLjgl17e0grKZrKxcE3ueKY0pc/sGwxchBtIwpAB4bcwhyWcmsvHNxhBB6Fi3FChcWLgguevb1MeMnlEcvOyshAYt+4Fpfcc5R9zMorLiykXwrZBFh3Sa08kXCEB37pIF3+KFBDBXJpCp8FXyV4F0SOEmSKTnTBoE+CjQ18mjdCUK8OdqxtpMyXaedp4lmh6Fkg51SMXFBmudzzRd9IYEpjaEWBc+FNjj6WyNUxa4AJWQiAIVMNUTOYCR02soN8vhQ3L3R4kV8PDalRweglp0xTfiUaw5hEOPC4dYaHfZVKWWroE2KY/dlvHYxqC4VJW5BG0T333ONHe7lBjW2wco+aFKA3BjQQE3IAMXMOaaNpYELDJrkcgD6ljzgMAhEmoL0AAYoXJYVQAJDojyfR5DjttNN0pOcCzHD6lwgsoKKGQfF79nVpu/qQezaF06xVGVEMjwrQWKwBbFypuQJEDWZlSNZxgmh4lIX3bs8y4QgKxfyKy8+xeODayOHCLmucaGsulIIqpy86xoGhjxl2WBM7/UjTHsLEJM6pCU3RC4QX1ammheNuEjXt3QBOhHCKJcoUWJZ4B5BSI/wOkNixy3PWLcYV2Xy6Zj9XwA/83/KoWMk9BwTOb/rcqXsphh9yexVidkQqZThUjjFPeRmuceSBkqrxAOgZZ5wBKE4ZRQGJV0iM07TTfviglFFBqjyeoFHLDn0gGA9mj/AV6MPkjZtZBeEAw0ZtZyENLBCiCSmESBEGoZ6Tcm1tFvqc4qs1mfDpT/y2u2U7eHhnXNFIDPzYx5GIBJwCwEKTTl6ARC4vxpufq2miiV9/yObPf/WSjbKrniyUGlRIVzTUcKL3sOG5IyLNyZ1qxjVKYcaqcGQOBvnmF0X8Mqu82FSCskUZgYQQgo1S1tCri8qLcJQRBrQHACIVL4Z9wDJWLWxEJiTqT4zMMiJGgSDHxywGyRUHC2J0CZ6nPAWO7AWepvzKu+jKo3qAgVn8eIYQCsFemK0NKmWAbRkhFDs8XlcoL1MZrLsnSPdYcWYIrT58qXoBkxgtcumFAPv05SN9zKKbAjbJJcnhEvVC1a/sSxt9QoevxUUFnB4iZx8avrCMfdNFbMCI1sDoC2vQ6cgi9lnIlLlIh33WRIV0dHj9VFVCUG00WVAQLvmSfnh4xBTWKFNg2ZDnToxgY6rc+F7KpSyyz3Xfshpy6phEWeBH+uf7aCMRwSkiGY0recK4ejKM+1N9u6xpyjS1AuFO0eRC+L4U5VSYfbmKbYXIkQNUUdhr4cnOvnhF7Wsd2ymIThQS0ZsiGGU3EhhHGqI8bfFWpeIEHnIBUrMuj2YV49aMYEBOU+C3fFFGr2r2eClN+BQUePhkh4IKnv2k00qhGDOVNlsVJlXR+tFDCyrD/uuuFeizuKgdCMRv5vuEwiMd9p0BkkVAvSrKBHAViueUYYN6WSQ3sRDHr+LQ1pIUTnc9yBj0cY814wTR0qafZk2zbJn/sFOqKNjYy2YDL1PGAFOCFSO6ITSi+GVWn+BLT3u8ggoVkLg2GwwnW2RLG7DDl2KVbLHDrzFwZZpC4lLxhZxmB/zaWsXbqKzh8ax0aEUFqqqgtTdljkShCPhl36VSAMDkxpvQlJRnkC2wueWXdTyQa/gsyKC4ILHL32n5U2a3gkohmxoywJQZIWeWL0WGeZcwMyIusZAbBG55JuofxEJbsSIEaa1n338YKgocOMko2fkDvW+kbDZ+DXPWuVlUX+ksKocDj4rdRkchVR+YNbG8kRgtMgcD7y6pUZAql/Knb/SZmE3NdHAdWrsAUxzuKgJjXJAeAdIpSSTitJdTW6RQzEghVIjKxS6UeWpwB4PcKCnPfX5RoRD1H/wgyfo8/L9OKh4qdSkEOaDPBX6Y9UaIfTib/TZgRrVxzbhM4JBN3s1+HjUDnMaVeIcLBgFmn9DPkVhiOQ7ZkTIu2IRcG8i32lJqLoXGCB32eWHZJSrEomIEQsFGQlyhDjn5Qg5lPDjwLF7kmOvly5k1j9G+YKMcRXrYLU3oMarxMMCyMMlnE6tDUZMiWn0YwtYd7jKKDvs1FsRT+lNydsCVcgoA6W/99y/zS6AUIYpllFA1i4dHPEoeIhCHWQBsZwdOBzvipwOwwsKvYuJCVJKBIzrWknf66adLEqHIBazVWHOpvZArQ2pIUFizBQy95C5T7sqWvcrXLfkgccuYiV+X9rorZ4ICXgjmq71yTxNyZ6PCA9pRyFwIULWpm4ZoEoGAYSOcCkWAolDBwpQ8ZcqOh1S1IuumLNf0VbayQ441lhjJkfBdAnnTTTf5OoAFl7aoP2BgLl8VDTy48hbVXmAs6EsEevWJS5CwUVPZq07Uk2Ap0wSJgpQp39kDkWNK7nkYgWLNt7NonVmxX+6tuzulPyVnwV721SWirSFwFomzQ03Yq9HF79/78yrjQKL5DEkwbA+VveyEJDvZZ0SevCEpFzbVHwsYl29x8oV0ckaskWWXamaKhDJTFHihw0hOrVvgy9o3pc4O250zaIGfNs7uzR+5Y99VYXJhInZXobi0Hox12fdG5F2mbPbQ1wwu8zggeT7ym3LFQUcgQmYqzO7Sifbmejr0swYDfnA17PNoDTb85T2P8ewsOzGfhQJEo6SMiFiY/clo1+nFmrFBHug8JZe8FehP2dEidnWuPrz6ZVBBhEz8EHtoBpp+8twZJxbFFs5y6ccHHLnVgU0cidCbZmw6RzEFWxRBmkyNjZBIHnkSPLagQ646QYoKhUiNxMto8BgPFTm/3riLa8gtAJZsZm10d+Cxhj9CbI9nCzTGcyHkiNDG8kKHzbKeX/K21yeEDhvxEJ+qxF8t++qLHBK0t3BuYwEaxiRtqZ4KB05yhxBaOPPlpbl0uKw6WWaKnVlhgYgpi9BbdGgyj2drNZGD0jmlPyWHJqYgDi47ATIe2JcSaAbjJCogzZB0plaF2VvwydkXudcdhxSCGk28GHt0XIZ/WEN0Fir3kse+tqaTsrxqff8+23nnnedvpNS9KJTOMMI+O8EeeNrrM6OFmouxbCpT4yFsnnfDjkUVU42OLVBV8X3+SJ87voyrsX2UJv3wuxV7YYMEb5BrGBKXbRn54jfY2XSZfWoL5bjCQDZpqkju/GOxjFc/A5Jds+++XUtVzkRSYCL3b7Cee+65VTdYyaf0p+QxDo20caQC+FLBCnyUjsuQpQwW9gnpe7dtMc7BUJFJylMbMdVMKnhnVKZQQYix7UowFvKbDkl2nKt4rQWwD8X+Lk/a1FaZY7lGLwSMu5VkGCkl2eE0egkbh5JhXXfZkrJFM8NllsUYNn6HMjVCIB0yXVd0rgTtHRXW9u7CMPRxld8IwUMI8+tcOOohv3zR70xTx/rtmTWB6C632LEl/C5n/8kD7aJ1XUrE49OT95WAJsyokdBlg9qW9pKXaZKxgK+ZJzD4itbCoSeKJGuozD7EgwWmrLsUQPrl4D/KVSQvLEQc49nH4Cgj8OoHalP2VaSviyg4SoZ4m5FoJSzYjFPw6wrhKBTr+JGhIs3jPJxZqjz9B/kAFyw5v3CyM/ATkqwApzEpC7DlqMrAs10ZQWDAsqPVSbrFeLdGZcQebMl7GlIOrWIyyz1qHTSD6reQ66+/vl6aPQodPeyIbGsnYcXLPXAJ+RiRUzDYnb15+K/YjMSRpAZ7dUChQ5n6e49QqlfKUNJhcLwXjyABBXe8UpQ2dsin9BeVo9jeQVbge/yxpvhiYcX24wHmKslGyROysRf7XhkJM27h4Neu0Twk3YXfeowTj4Ve6hkkL3kKIjUSB8ayLwUrxikRPJqdinholjgG2RFvck8hDVz6pEBx1DP5Jako8VYSB55STC5w7nQFhO0Vi09gvXsIfwmpxwf3o5Pmw5kNvR4TXTrXmjTJnaObY6MLYv+Btl8YqVU6TKfPvs+xaAUuFxbuSpLnCzsOu+Ld2i5NSULHuZCsRcILSfp5cXdKzk5BZqGSZcdGeQ2JqtLiuZ6y4y6ouePdIWRCvyPpB2CybxEh7OCHvste9ssNBfmzPbUMwsOUUpg3PDvBWd3jjQuS4FkU+BROEcl3r+dt4QI2BtWuXSx0tiBXOnBGsrUt1uTQ9pCh5kiBKcfo8yEXi0M1l+uqFk7HbGIVedQ7m6itZ4b/9e9jq8fyTcI9HDzN35/9F1csIMKZEBRnOtVfOs41JdbouwxTuF3CNOyPLRYcpW8NLrPdJWe/9ZScMvuzKOd7fdhpl1uIhkoyipfaovZDHgC97sN/DGanGmXKnIhJdtzSzTRRoS5HmOx31wJ+ZxvNcmow2K5Y2QkPL+SOHMl36ymcIUSsBY/ssC/lzLp0kFsPHnAYmOybL9VHl/Rttx5z2mUSMNwdcjpNuKw1X5fwVBg+AWHNJR5p9HpbXdvZHuZ6B3ep/jIHDbnKCxCa0qk/4t2t5ofFQjnX9BUleVF1V8zwLLTTXfpDDurY9e/y/LKjbqqMLLemb06kA/wK7Az2FUoWKAu/2K3N43Jp7aDvTHN8sI26YoEZnmaStQxJv0ts0/eBpkez7Q52kEx/xE4y1n/jQcoFYhf9IgpJpWAjR+HszCnvatf87nsynFCLE08hcbW3QRtvtrjMQhGNHus5zkLeZxOrGGLKq4P/N4afEcgdgz4WXTYk04eM43Dke37H8l4aRIW4ijrfxUmH40DEURaKoWKvzvJStAv1k4en4Zydf5dneWSC6+xbxKlmECA8Ff2UHfrgeWhaOKhp+uhzmRcLpioL6xFs+OOtTig6azr+7acU2Izq3lrwKRx9juTikmZmGzZTOHNaHVOGOX7UKyFH+XLODiEeuBAaHZB6CJSL6kaFqdRRD8yWX0bo93KS2fyiJft/FVYaqtJz/fLLL+8TH957v+OjAaZErJkOAROB4M8BpcdZjJf45GYDcK2DGxQUF6EOWKgPxsh0yWgv/fxiduTVrSm5KLIv9wvto3JUQEVPsgI77Ivr5ptvBrtmDY9zmaNgPfKKKzOgGGMSAICVTnyWUUJTimVjyfdkLNBxy5H9gR/hqVVSU/HChjqFKNjKVLn41yX8O/ujowKZHUkJD3eVb2y4WxcBEG/pszkef0nC2bi1phwVFrM/HSGCqRLRMT5JugyBs1KQZgPTLKXsyUXf/jZCIPf2hixPzs0Y26uMgbuO5LhcYr8EyHSLEUn2uQaAkQYDOxkEJv0peRUg/lzDWUTs+3x3wQUX1Ev8hmTKThUsat9cqwOTI4RFPeLte7IwE7rbWiZ6iIQWqkqNqcpodKbywiqeq63KC+Y2QtuomMKZfMTLr72M+wAh3hIKOR6yHLzqAxJ40i+i6sP28YALp3P8jw/awWOtuOpkRmb/ctqgo3Hikm8MhpWSeneLM3an9FcsLz2lsJSzL6rWo+yg9BTgJbhSYmp6NFus2H50LMQ/pa8ipTCPvVvYK94p/fEREni15T/Vsuv/wcPCt4LGSfTKtAWDYFQ6FlJAHwnxENrYm8KJz1K70I7tU/r/bflSP6T3dxRig6wft/1o74d9fwXQpV/C/SDvh2s/8k/pT8n9kC5tmNIuZiaDfg939lcAKPCUlGZdxTu5X+b9MR0vANDRHDD4yxlGpuz/X+X+qIZrv9IjvXgB433Kjr9eggFULPmjF38jgBnwpvRXIBeRjXosv8JkdiHP2oyOAzx/KNHfKQzeCN2aso+l/spFLEYATcZZmNL/b8v/Fzx6nxufP/KAAAAAAElFTkSuQmCC",
      "image/jpeg": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=200x50>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Question: What does the text say?\n",
      "Ground Truth: 000073\n",
      "Moondream: The text says \"number 0073\" on a white background.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Number of times to repeat the training dataset. Increasing this may cause the model to overfit or\n",
    "# lose generalization due to catastrophic forgetting. Decreasing it may cause the model to underfit.\n",
    "EPOCHS = 2\n",
    "\n",
    "# Number of samples to process in each batch.\n",
    "# Set this to the highest value that doesn't cause an\n",
    "# out-of-memory error.\n",
    "# Decrease it if you're running out of memory.\n",
    "# Batch size 8 currently uses around\n",
    "# 15 GB of GPU memory during fine-tuning.\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Number of batches to process before updating the model. You can use this to simulate a higher batch\n",
    "# size than your GPU can handle. Set this to 1 to disable gradient accumulation.\n",
    "GRAD_ACCUM_STEPS = 1\n",
    "\n",
    "# Learning rate for the Adam optimizer. Needs to be tuned on a case-by-case basis.\n",
    "# As a general rule of thumb, increase it by 1.4 times each time you double\n",
    "# the effective batch size.\n",
    "#\n",
    "# Source: https://www.cs.princeton.edu/~smalladi/blog/2024/01/22/SDEs-ScalingRules/\n",
    "#\n",
    "# Note that we linearly warm the learning rate up from 0.1 * LR to LR over\n",
    "# the first 10% of the # training run, and then decay it back to 0.1 * LR over\n",
    "# the last 90% of the training run using a cosine schedule.\n",
    "LR = 3e-5\n",
    "\n",
    "# Whether to use Weights and Biases for logging training metrics.\n",
    "USE_WANDB = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from bitsandbytes.optim import Adam8bit\n",
    "import math\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "\n",
    "# The current version of moondream uses \"<END>\" to denote the end of a response. In the future this\n",
    "# will be replaced with a special token.\n",
    "ANSWER_EOS = \"<END>\"\n",
    "\n",
    "# Number of tokens used to represent each image.\n",
    "IMG_TOKENS = 729\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [sample[\"image\"] for sample in batch]\n",
    "    images = torch.stack(moondream.vision_encoder.preprocess(images))\n",
    "    images = rearrange(images, \"b c (h p1) (w p2) -> b (h w) (c p1 p2)\", p1=14, p2=14)\n",
    "\n",
    "    labels_acc = []\n",
    "    tokens_acc = []\n",
    "\n",
    "    for sample in batch:\n",
    "        toks = [tokenizer.bos_token_id]\n",
    "        labs = [-100] * (IMG_TOKENS + 1)\n",
    "\n",
    "        for qa in sample[\"qa\"]:\n",
    "            q_t = tokenizer(\n",
    "                f\"\\n\\nQuestion: {qa['question']}\\n\\nAnswer:\", add_special_tokens=False\n",
    "            ).input_ids\n",
    "            toks.extend(q_t)\n",
    "            labs.extend([-100] * len(q_t))\n",
    "\n",
    "            a_t = tokenizer(\n",
    "                f\" {qa['answer']}{ANSWER_EOS}\", add_special_tokens=False\n",
    "            ).input_ids\n",
    "            toks.extend(a_t)\n",
    "            labs.extend(a_t)\n",
    "\n",
    "        tokens_acc.append(toks)\n",
    "        labels_acc.append(labs)\n",
    "\n",
    "    max_len = -1\n",
    "    for labels in labels_acc:\n",
    "        max_len = max(max_len, len(labels))\n",
    "\n",
    "    attn_mask_acc = []\n",
    "\n",
    "    for i in range(len(batch)):\n",
    "        len_i = len(labels_acc[i])\n",
    "        pad_i = max_len - len_i\n",
    "\n",
    "        labels_acc[i].extend([-100] * pad_i)\n",
    "        tokens_acc[i].extend([tokenizer.eos_token_id] * pad_i)\n",
    "        attn_mask_acc.append([1] * len_i + [0] * pad_i)\n",
    "\n",
    "    return (\n",
    "        images.to(dtype=dtype),\n",
    "        torch.stack([torch.tensor(t, dtype=torch.long) for t in tokens_acc]),\n",
    "        torch.stack([torch.tensor(l, dtype=torch.long) for l in labels_acc]),\n",
    "        torch.stack([torch.tensor(a, dtype=torch.bool) for a in attn_mask_acc]),\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_loss(batch):\n",
    "    images, tokens, labels, attn_mask = batch\n",
    "\n",
    "    images = images.to(device)\n",
    "    tokens = tokens.to(device)\n",
    "    labels = labels.to(device)\n",
    "    attn_mask = attn_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        img_embs = moondream.vision_encoder.encoder(images)\n",
    "        img_embs = moondream.vision_encoder.projection(img_embs)\n",
    "\n",
    "    tok_embs = moondream.text_model.get_input_embeddings()(tokens)\n",
    "    inputs_embeds = torch.cat(\n",
    "        (tok_embs[:, 0:1, :], img_embs, tok_embs[:, 1:, :]), dim=1\n",
    "    )\n",
    "\n",
    "    outputs = moondream.text_model(\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        labels=labels,\n",
    "        attention_mask=attn_mask,\n",
    "    )\n",
    "\n",
    "    return outputs.loss\n",
    "\n",
    "\n",
    "def lr_schedule(step, max_steps):\n",
    "    x = step / max_steps\n",
    "    if x < 0.1:\n",
    "        return 0.1 * LR + 0.9 * LR * x / 0.1\n",
    "    else:\n",
    "        return 0.1 * LR + 0.9 * LR * (1 + math.cos(math.pi * (x - 0.1))) / 2\n",
    "\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": DataLoader(\n",
    "        datasets[\"train\"],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "    ),\n",
    "    \"val\": DataLoader(\n",
    "        datasets[\"val\"],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        collate_fn=collate_fn,\n",
    "    ),\n",
    "}\n",
    "\n",
    "moondream.text_model.train()\n",
    "moondream.text_model.transformer.gradient_checkpointing_enable()\n",
    "\n",
    "total_steps = EPOCHS * len(dataloaders[\"train\"]) // GRAD_ACCUM_STEPS\n",
    "optimizer = Adam8bit(\n",
    "    [\n",
    "        {\"params\": moondream.text_model.parameters()},\n",
    "    ],\n",
    "    lr=LR * 0.1,\n",
    "    betas=(0.9, 0.95),\n",
    "    eps=1e-6,\n",
    ")\n",
    "\n",
    "if USE_WANDB:\n",
    "    import wandb\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"moondream-ft\",\n",
    "        config={\n",
    "            \"EPOCHS\": EPOCHS,\n",
    "            \"BATCH_SIZE\": BATCH_SIZE,\n",
    "            \"GRAD_ACCUM_STEPS\": GRAD_ACCUM_STEPS,\n",
    "            \"LR\": LR,\n",
    "        },\n",
    "    )\n",
    "\n",
    "i = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch in tqdm(dataloaders[\"train\"], desc=f\"Epoch {epoch + 1}/{EPOCHS}\"):\n",
    "        i += 1\n",
    "\n",
    "        loss = compute_loss(batch)\n",
    "        loss.backward()\n",
    "\n",
    "        if i % GRAD_ACCUM_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            lr = lr_schedule(i / GRAD_ACCUM_STEPS, total_steps)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = lr\n",
    "\n",
    "        if i % 100 == 0 and USE_WANDB:\n",
    "            # Calculate validation loss\n",
    "            val_loss = 0\n",
    "            for val_batch in tqdm(dataloaders[\"val\"], desc=\"Validation\"):\n",
    "                with torch.no_grad():\n",
    "                    val_loss += compute_loss(val_batch).item()\n",
    "            val_loss /= len(dataloaders[\"val\"])\n",
    "\n",
    "        if USE_WANDB:\n",
    "            wandb.log(\n",
    "                {\"loss/train\": loss.item(), \"lr\": optimizer.param_groups[0][\"lr\"]}\n",
    "                | ({\"loss/val\": val_loss} if i % 100 == 0 else {})\n",
    "            )\n",
    "\n",
    "if USE_WANDB:\n",
    "    wandb.finish()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 1/2:   0%|          | 0/750 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/j2y/miniconda3/envs/tiny/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Epoch 1/2:   0%|          | 0/750 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.14 GiB. GPU 0 has a total capacty of 12.00 GiB of which 347.40 MiB is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 9.87 GiB is allocated by PyTorch, and 738.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m/home/j2y/dev_repo/VLM/moondream/experiments/finetune2.py:145\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(dataloaders[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m], desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mEPOCHS\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    143\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[39m=\u001b[39m compute_loss(batch)\n\u001b[1;32m    146\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m GRAD_ACCUM_STEPS \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32m/home/j2y/dev_repo/VLM/moondream/experiments/finetune2.py:83\u001b[0m\n\u001b[1;32m     78\u001b[0m tok_embs \u001b[39m=\u001b[39m moondream\u001b[39m.\u001b[39mtext_model\u001b[39m.\u001b[39mget_input_embeddings()(tokens)\n\u001b[1;32m     79\u001b[0m inputs_embeds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m     80\u001b[0m     (tok_embs[:, \u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m, :], img_embs, tok_embs[:, \u001b[39m1\u001b[39m:, :]), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 83\u001b[0m outputs \u001b[39m=\u001b[39m moondream\u001b[39m.\u001b[39;49mtext_model(\n\u001b[1;32m     84\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m     85\u001b[0m     labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m     86\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     89\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\u001b[39m.\u001b[39mloss\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/vikhyatk/moondream2/2b705eea63f9bff6dae9b52c2daeb26bc10e4aeb/modeling_phi.py:1131\u001b[0m, in \u001b[0;36mPhiForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Enable model parallelism\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     shift_labels \u001b[39m=\u001b[39m shift_labels\u001b[39m.\u001b[39mto(shift_logits\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> 1131\u001b[0m     loss \u001b[39m=\u001b[39m loss_fct(shift_logits, shift_labels)\n\u001b[1;32m   1133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1134\u001b[0m     output \u001b[39m=\u001b[39m (logits,) \u001b[39m+\u001b[39m outputs[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.10/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1180\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1181\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.10/site-packages/torch/nn/functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3052\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3053\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.14 GiB. GPU 0 has a total capacty of 12.00 GiB of which 347.40 MiB is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 9.87 GiB is allocated by PyTorch, and 738.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "moondream.save_pretrained(\"checkpoints/moondream-ft\")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "",
     "evalue": "",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " Now that training has completed, let's inspect a few samples and calculate accuracy."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "moondream.eval()\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for i, sample in enumerate(datasets[\"test\"]):  # type: ignore\n",
    "    md_answer = moondream.answer_question(\n",
    "        moondream.encode_image(sample[\"image\"]),\n",
    "        sample[\"qa\"][0][\"question\"],\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    if md_answer == sample[\"qa\"][0][\"answer\"]:\n",
    "        correct += 1\n",
    "\n",
    "    if i < 3:\n",
    "        display(sample[\"image\"])\n",
    "        print(\"Question:\", sample[\"qa\"][0][\"question\"])\n",
    "        print(\"Ground Truth:\", sample[\"qa\"][0][\"answer\"])\n",
    "        print(\"Moondream:\", md_answer)\n",
    "\n",
    "print(f\"\\n\\nAccuracy: {correct / len(datasets['test']) * 100:.2f}%\")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "",
     "evalue": "",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}